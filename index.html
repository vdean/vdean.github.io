<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="style.css">
  <title>Victoria Dean</title>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
    ga('create', 'UA-83215168-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9TCBDE5WRW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    
    gtag('config', 'G-9TCBDE5WRW');
  </script>
</head>
<body>
  <div style="width:800px; margin:auto; margin-bottom:100px">
    <div style="min-height:275px">
      <img src="images/picture.png" width=225 style="border-radius:15px;float:right;">
      <div style="padding-right:265px">
	<h1>Victoria Dean &nbsp;<font size="5" style="color:#f27a6b;vertical-align:20%;">she/her</font></h1>
	<p>Hello! I'm an Assistant Professor of Computer Science at Olin College of Engineering. I got my PhD in the <a href="http://ri.cmu.edu">Robotics Institute</a> at Carnegie Mellon University advised by <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>. I work on exploration and benchmarking in reinforcement learning and robotics.</p>
	<p>In Fall 2021, I interned with <a href="https://www.cs.mcgill.ca/~dprecup/">Doina Precup</a> at DeepMind Montreal. I got my BS in Computer Science and Engineering from MIT. I have also spent time at <a href="http://waymo.com">Waymo</a>, <a href="http://deepgenomics.com">Deep Genomics</a>, <a href="http://counsyl.com">Counsyl</a>, <a href="http://google.com">Google</a>, and <a href="http://coursera.org">Coursera</a>.</p>
	<p>I am always looking for students, especially those from underrepresented groups, to collaborate with. If you're interested, please email me.</p>
	<div style="justify-content:space-between;display:flex; padding: 0px 120px 0px 120px"><a href="mailto:vdean@olin.edu">vdean@olin.edu</a><a href="CV.pdf">CV</a><a href="https://scholar.google.com/citations?user=oi6MLcYAAAAJ">Scholar</a><a href="https://twitter.com/vdean314">Twitter</a></div>
      </div>
    </div>
    <div id="news">
      <h2>News</h2>
      <p style="text-align:left">
	Our paper, <a href="https://toto-benchmark.org/">Train Offline, Test Online: A Real Robot Learning Benchmark</a>, was accepted to ICRA 2023 and received the Best Paper Award at NeurIPS Broadening Collaborations in Machine Learning Workshop.<br><br>
	I am co-organizing the <a href="https://sites.google.com/view/ldod2023/home">2nd Workshop on Learning from Diverse, Offline Data</a> (L-DOD) at ICRA 2023.<br><br>
	I completed the <a href="https://www.cmu.edu/teaching/graduatestudentsupport/futurefacultyprogram.html">Future Faculty Program</a> via the Eberly Center for Teaching Excellence & Educational Innovation.<br><br>
      </p>
    </div>
        <div id="teaching">
	  <h2>Teaching</h2>
	  <div class="research_item">
	    <img src="images/graphic.png" class="image">
	    <h3 style="margin-bottom:0px"><a href="https://vdean.github.io/16-735-ethics-robotics.html">Ethics and Robotics (16-735)</a></h3>
	    Carnegie Mellon University<br>
	    Instructor of Record, Spring 2021 [<a href="16-735/Ethics_and_Robotics_SIGCSE.pdf"\
>SIGCSE paper</a>]
	  </div>
	  <div class="research_item">
            <img src="images/rl.png" class="image">
            <h3 style="margin-bottom:0px"><a href="https://sites.google.com/view/16-881-cmu/home">Deep Reinforcement Learning for Robotics (16-881)</a></h3>
	    Carnegie Mellon University<br>
	    Teaching Assistant, Spring 2020</div>
	  <div class="research_item">
            <img src="images/gatorbotics.jpg" class="image">
            <h3 style="margin-bottom:0px"><a href="http://gatorbotics.weebly.com/">FIRST Robotics Competition</a></h3>
	    Castilleja Gatorbotics<br>
	    Head Coach, 2017 - 2018
	    </div>
	  <div class="research_item">
            <img src="images/deeplearning.png" class="image">
            <h3 style="margin-bottom:0px"><a href="http://introtodeeplearning.com/">Introduction to Deep Learning (6.S191)</a></h3>
	    Massachusetts Institute of Technology<br>
	    Lecturer and Co-Chair, January 2017 [<a href="https://www.youtube.com/watch?v=6QewMQT4iMM">video</a>]</div>
	  <div class="research_item">
            <img src="images/buzzi.png" class="image">
            <h3 style="margin-bottom:0px"><a href="https://misti.mit.edu/global-teaching-labs">MIT Global Teaching Labs: Python and Machine Learning</a></h3>
	    Istituto Tecnico Industriale Statale Tullio Buzzi di Prato<br>
	    Instructor, January 2016</div>
	  <div class="research_item">
            <img src="images/helloworld.jpg" class="image">
            <h3 style="margin-bottom:0px"><a href="https://swe.mit.edu/outreach/middle_school/helloworld.html">#HelloWorld: Web Development</a></h3>
	    MIT Society of Women Engineers<br>
	    Lead Instructor, 2014 - 2017 [<a href="https://drive.google.com/open?id=0Bw9g8vmIO_peflh5WlpEdHBESEdiakdIOVpjZTZPY3g3WWRJMUkyVTRheHFXVDROZUFJLWM">slides</a>]</div>
	  <div class="research_item">
            <img src="images/codeforgood.png" class="image" style="margin-top:10px;margin-bottom:10px">
            <h3 style="margin-bottom:0px"><a href="http://codeforgood.mit.edu">Code for Good (6.S187)</a></h3>
	    Massachusetts Institute of Technology<br>
	    Instructor of Record and Founder, 2014 - 2017</div>
	  <div class="research_item">
            <img src="images/eecs.jpeg" class="image">
            <h3 style="margin-bottom:0px"><a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-01sc-introduction-to-electrical-engineering-and-computer-science-i-spring-2011/">Introduction to Electrical Engineering and Computer Science (6.01)</a></h3>
	    Massachusetts Institute of Technology<br>
	    Student Lab Assistant, Spring 2014</div>
	  <div class="research_item">
            <img src="images/khanacademy.png" class="image">
            <h3 style="margin-bottom:0px"><a href="https://www.khanacademy.org/talks-and-interviews/schools-using-khan-academy/v/khan-academy-s-discovery-lab-offers-hands-on-learning">Discovery Lab</a></h3>
	    Khan Academy<br>
	    Teaching Assistant, Summer 2012</div>
    </div>
    <div id="research">
      <h2>Research</h2>
      <div class="research_item">
	<img src="images/toto.gif" class="image">
	<h3 style="margin-bottom:0px">Train Offline, Test Online: A Real Robot Learning Benchmark</h3>
	<p>Gaoyue Zhou*, <b>Victoria Dean*</b>, Mohan Kumar Srirama, Aravind Rajeswaran, Jyothish Pari,
Kyle Hatch, Aryan Jain, Tianhe Yu, Pieter Abbeel, Lerrel Pinto, Chelsea Finn, Abhinav Gupta<br><br>
	  Train Offline, Test Online (TOTO) provides remote users with access to shared robots for evaluating methods on common tasks and an open-source dataset of these tasks for offline training. We present results on TOTO comparing five pretrained visual representations and four offline policy learning baselines, remotely contributed by five institutions. We release the benchmark for additional submissions from any user, enabling easy, direct comparison to several methods without the need to obtain hardware or collect data.
	  <i>CMU, Meta AI, NYU, Stanford, UC Berkeley | ICRA 2023.</i> [<a href="https://toto-benchmark.org/">website</a>, <a href="https://o\
penreview.net/forum?id=W_TkB-1eNbs">blue sky paper</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/c-bet.png" class="image">
	<h3 style="margin-bottom:0px">Interesting Object, Curious Agent: Learning Task-Agnostic Exploration</h3>
	<p>Simone Parisi*, <b>Victoria Dean*</b>, Deepak Pathak, Abhinav Gupta<br><br>
	  We propose a paradigm change in the formulation and evaluation of task-agnostic exploration. In this setup, the agent first learns to explore across many environments without any extrinsic goal in a task-agnostic manner. Later on, the agent effectively transfers the learned exploration policy to better explore new environments when solving tasks. In this context, we evaluate several baseline exploration strategies and present a simple yet effective approach to learning task-agnostic exploration policies. <i>CMU and FAIR | NeurIPS 2021.</i> [<a href="https://proceedings.neurips.cc/paper/2021/file/abe8e03e3ac71c2ec3bfb0de042638d8-Paper.pdf">paper</a>, <a href="https://github.com/sparisi/cbet/">code</a>]</p>
      </div>
      <div class="research_item">
        <img src="images/kitchenshift.png" class="image">
        <h3 style="margin-bottom:0px">KitchenShift: Evaluating Zero-Shot Generalization of Imitation-Based Policy Learning Under Domain Shifts</h3>
	<p>Eliot Xing, Abhinav Gupta, Sam Powers*, <b>Victoria Dean*</b><br><br>
	  We propose a testing protocol for evaluating the generalization of policy learning methods. We implement and evaluate KitchenShift, an instance of our testing protocol that applies domain shifts to a realistic kitchen environment. Using KitchenShift, we evaluate imitation and representation learning methods used in current policy learning approaches and find that they are not robust to minor changes in the environment. [<a href="https://openreview.net/forum?id=DdglKo8hBq0">paper</a>]</p><br>
      </div>
      <div class="research_item">
	<img src="images/audio-curiosity.png" class="image">
	<h3 style="margin-bottom:0px">See, Hear, Explore: Curiosity via Audio-Visual Association</h3>
	<p><b>Victoria Dean</b>, Shubham Tulsiani, Abhinav Gupta<br><br>
	We introduce See, Hear, Explore (SHE): a new curiosity formulation using multimodal self-supervision. SHE rewards actions that generate novel associations between different sensory modalities (pixels and sounds). Our results on Atari and AI Habitat show that SHE allows for more exploration, is more sample-efficient, and is more robust to noise compared to existing curiosity baselines on these environments. <i>CMU and FAIR | NeurIPS 2020.</i> [<a href="resources/see-hear-explore-neurips-2020.pdf">paper</a>, <a href="audio-curiosity.html">website</a>, <a href="https://youtu.be/DMiW5hwsoeo">video</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/carl.png" class="image">
	<h3>CaRL: Combining Imitation Learning with Reinforcement Learning</h3>
	<p>Used reinforcement learning to improve upon imitation learned policies for trajectory generation, with the goal of both learning from observed behavior and generalizing beyond it. Built upon work presented in <a href="https://arxiv.org/abs/1812.03079">this paper</a>. <i>Waymo 2018.</i></p>
      </div>
      <div class="research_item">
	<img src="images/speed_limit.png" class="image">
	<h3>Onboard Text Detection</h3>
	<p>Developed and deployed an onboard text detection system that allows cars to recognize a set of important words to disambiguate a number of situations. Used an accurate but expensive Google OCR system to train a low-latency onboard model. <i>Waymo 2017.</i> [<a href="https://patents.google.com/patent/US10699141B2/en">patent</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/motif.png" class="image">
	<h3>Deep Learning for Branch Point Selection in RNA Splicing</h3>
	<p>Built BRANCHR, a state-of-the-art model for predicting branch point selection, a crucial step in RNA splicing. <i>Deep Genomics | WiML and MLCB (oral) at NeurIPS 2016. </i> [<a href="resources/MLCB2016_paper.pdf">paper</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/prediction_diagram.png" class="image">
	<h3>Predicting the Future: Generative Models for Video</h3>
	<p>Experimented with CNN models to predict a frame given past frames. Presented poster at SuperUROP poster session. <i>MIT Computer Vision group | EECSCon 2016.</i> [<a href="resources/video_poster.pdf">poster</a>]</p>
      </div>
      <div class="research_item" style="padding-bottom:0px">
	<img src="images/LAE.png" class="image">
	<h3>Automated Search for Lyman Alpha Emitters</h3>
	<p>Developed pattern matching software to search spectra for distant galaxies. Presented poster at 2013 American Astronomical Society meeting. Intel Science Talent Search semifinalist. <i>UC Santa Cruz | American Astronomical Society Meeting 2012 and 2013.</i> [<a href="resources/intel_paper.pdf">paper</a>, <a href="http://adsabs.harvard.edu/abs/2013AAS...22114742D">poster 1</a>, <a href="http://adsabs.harvard.edu/abs/2012AAS...21934004M">poster 2</a>]</p>
      </div>
    </div>
    <div id="other">
      <h2>Other</h2>
      I've organized a few workshops: <a href="https://sites.google.com/andrew.cmu.edu/cloud-robotics-benchmarking/">Robot Learning in the Cloud</a> and <a href="https://sites.google.com/view/l-dod-rss2022">L-DOD</a> at RSS '22, <a href="https://montrealrobotics.ca/diffcvgp/">DiffCVGP</a> at NeurIPS '20.<br><br>
      With the Dean's PhD Advisory Committee, I co-wrote a public letter, <a href="https://docs.google.com/document/d/1-WRYuLT-xQFOiv1yyxMUdFV26RGB9_jOFgz7Y_xaWuk">Towards Anti-Racist Change in the School of Computer Science</a>, which amassed more than 600 signatures in 2020.<br><br>
      I've released my NSF GRFP application statements for future applicants [<a href="resources/NSF_Personal_Statement_Victoria_Dean.pdf">personal</a>, <a href="resources/NSF_Research_Statement_Victoria_Dean.pdf">research</a>].<br><br>
      Outside of research, I enjoy <a href="https://www.goodreads.com/review/list/97438434?shelf=favorites">reading</a>, <a href="https://mitathletics.com/sports/wcrewlt/roster/victoria-dean/5620">rowing</a>, and <a href="images/cookies.gif">experimental baking</a>.<br><br>
    </div>
  </div>
</body>
</html>
