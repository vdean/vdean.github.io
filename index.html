<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="style.css">
  <title>Victoria Dean</title>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
    ga('create', 'UA-83215168-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>
<body>
  <div style="width:800px; margin:auto; margin-bottom:100px">
    <div style="min-height:275px">
      <img src="images/picture.jpg" width=225 style="border-radius:15px;float:right;">
      <div style="padding-right:265px">
	<h1>Victoria Dean</h1>
	<p>Hello! I'm a 4th year PhD student in the <a href="http://ri.cmu.edu">Robotics Institute</a> at Carnegie Mellon University advised by <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>.  I work on exploration and task transfer in reinforcement learning. I am a 2020 recipient of the NSF GRFP.</p>
	<p>In Fall 2021, I interned with <a href="https://www.cs.mcgill.ca/~dprecup/">Doina Precup</a> at DeepMind Montreal. I completed my B.S. in Computer Science and Engineering at MIT. I have spent time at <a href="http://waymo.com">Waymo</a>, <a href="http://deepgenomics.com">Deep Genomics</a>, <a href="http://counsyl.com">Counsyl</a>, <a href="http://google.com">Google</a>, and <a href="http://coursera.org">Coursera</a>.</p>
	<p>I am always looking for students, especially those from underrepresented groups, to collaborate with. If you're interested, please email me.</p>
	<div style="justify-content:space-between;display:flex; padding: 0px 120px 0px 120px"><a href="mailto:vdean@cs.cmu.edu">vdean@cs.cmu.edu</a><a href="CV.pdf">CV</a><a href="https://github.com/vdean">Github</a><a href="https://twitter.com/vdean314">Twitter</a></div>
      </div>
    </div>
    <div id="news">
      <h2>News</h2>
      <p style="text-align:left">
	I gave a <a href="https://www.youtube.com/watch?v=zYDwnj_ghZM&t=3755s">Blue Sky Oral</a> on our paper, <a href="https://openreview.net/forum?id=W_TkB-1eNbs">Robots on Demand:
 A Democratized Robotics Research Cloud</a> at CoRL.<br><br>
	Our paper, <a href="https://proceedings.neurips.cc/paper/2021/file/abe8e03e3ac71c2ec3bfb0de042638d8-Paper.pdf">Interesting Object, Curious Agent: Learning Task-Agnostic Exploration</a>, was an oral at NeurIPS 2021.<br><br>
	I taught <a href="https://vdean.github.io/16-735-ethics-robotics.html">Ethics and Robotics</a> with <a href="http://www.cs.cmu.edu/~illah/">Illah Nourbakhsh</a> in Spring 2021. Our paper on this course, <a href="16-735/Ethics_and_Robotics_SIGCSE.pdf">Teaching Ethics by Teaching Ethics Pedagogy</a>, will appear at SIGCSE 2022. 
      </p>
    </div>
    <div id="research">
      <h2>Research</h2>
      <div class="research_item">
	<img src="images/c-bet.png" class="image">
	<h3 style="margin-bottom:0px">Interesting Object, Curious Agent: Learning Task-Agnostic Exploration</h3>
	<p>Simone Parisi*, <b>Victoria Dean*</b>, Deepak Pathak, Abhinav Gupta<br><br>
	  We propose a paradigm change in the formulation and evaluation of task-agnostic exploration. In this setup, the agent first learns to explore across many environments without any extrinsic goal in a task-agnostic manner. Later on, the agent effectively transfers the learned exploration policy to better explore new environments when solving tasks. In this context, we evaluate several baseline exploration strategies and present a simple yet effective approach to learning task-agnostic exploration policies. <i>CMU and FAIR | NeurIPS 2021.</i> [<a href="https://proceedings.neurips.cc/paper/2021/file/abe8e03e3ac71c2ec3bfb0de042638d8-Paper.pdf">paper</a>, <a href="https://github.com/sparisi/cbet/">code</a>]</p>
      </div>
      <div class="research_item">
        <img src="images/kitchenshift.png" class="image">
        <h3 style="margin-bottom:0px">KitchenShift: Evaluating Zero-Shot Generalization of Imitation-Based Policy Learning Under Domain Shifts</h3>
	<p>Eliot Xing, Abhinav Gupta, Sam Powers*, <b>Victoria Dean*</b><br><br>
	  We propose a testing protocol for evaluating the generalization of policy learning methods. We implement and evaluate KitchenShift, an instance of our testing protocol that applies domain shifts to a realistic kitchen environment. Using KitchenShift, we evaluate imitation and representation learning methods used in current policy learning approaches and find that they are not robust to minor changes in the environment. [<a href="https://openreview.net/forum?id=DdglKo8hBq0">paper</a>]</p><br>
      <div class="research_item">
	<img src="images/audio-curiosity.png" class="image">
	<h3 style="margin-bottom:0px">See, Hear, Explore: Curiosity via Audio-Visual Association</h3>
	<p><b>Victoria Dean</b>, Shubham Tulsiani, Abhinav Gupta<br><br>
	We introduce See, Hear, Explore (SHE): a new curiosity formulation using multimodal self-supervision. SHE rewards actions that generate novel associations between different sensory modalities (pixels and sounds). Our results on Atari and AI Habitat show that SHE allows for more exploration, is more sample-efficient, and is more robust to noise compared to existing curiosity baselines on these environments. <i>CMU and FAIR | NeurIPS 2020.</i> [<a href="resources/see-hear-explore-neurips-2020.pdf">paper</a>, <a href="audio-curiosity.html">website</a>, <a href="https://youtu.be/DMiW5hwsoeo">video</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/carl.png" class="image">
	<h3>CaRL: Combining Imitation Learning with Reinforcement Learning</h3>
	<p>Used reinforcement learning to improve upon imitation learned policies for trajectory generation, with the goal of both learning from observed behavior and generalizing beyond it. Built upon work presented in <a href="https://arxiv.org/abs/1812.03079">this paper</a>. <i>Waymo 2018.</i></p>
      </div>
      <div class="research_item">
	<img src="images/speed_limit.png" class="image">
	<h3>Onboard Text Detection</h3>
	<p>Developed and deployed an onboard text detection system that allows cars to recognize a set of important words to disambiguate a number of situations. Used an accurate but expensive Google OCR system to train a low-latency onboard model. <i>Waymo 2017.</i> [<a href="https://patents.google.com/patent/US10699141B2/en">patent</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/motif.png" class="image">
	<h3>Deep Learning for Branch Point Selection in RNA Splicing</h3>
	<p>Built BRANCHR, a state-of-the-art model for predicting branch point selection, a crucial step in RNA splicing. <i>Deep Genomics | WiML and MLCB (oral) at NeurIPS 2016. </i> [<a href="MLCB2016_paper.pdf">paper</a>]</p>
      </div>
      <div class="research_item">
	<img src="images/prediction_diagram.png" class="image">
	<h3>Predicting the Future: Generative Models for Video</h3>
	<p>Experimented with CNN models to predict a frame given past frames. Presented poster at SuperUROP poster session. <i>MIT Computer Vision group | EECSCon 2016.</i> [<a href="video_poster.pdf">poster</a>]</p>
      </div>
      <div class="research_item" style="padding-bottom:0px">
	<img src="images/LAE.png" class="image">
	<h3>Automated Search for Lyman Alpha Emitters</h3>
	<p>Developed pattern matching software to search spectra for distant galaxies. Presented poster at 2013 American Astronomical Society meeting. Intel Science Talent Search semifinalist. <i>UC Santa Cruz | American Astronomical Society Meeting 2012 and 2013.</i> [<a href="intel_paper.pdf">paper</a>, <a href="http://adsabs.harvard.edu/abs/2013AAS...22114742D">poster 1</a>, <a href="http://adsabs.harvard.edu/abs/2012AAS...21934004M">poster 2</a>]</p>
      </div>
    </div>
    <div id="teaching">
      <h2>Teaching</h2>
      <a href="https://vdean.github.io/16-735-ethics-robotics.html">Ethics and Robotics</a><br>Instructor of Record, Spring 2021<br><br>
      <a href="https://sites.google.com/view/16-881-cmu/home">Deep Reinforcement Learning for Robotics</a><br>Head Teaching Assistant, Spring 2020<br><br>
      <p style="text-align:left"><a href="http://gatorbotics.weebly.com/">FIRST Robotics Competition - Gatorbotics</a><br>Head Coach, 2017 - 2018<br><br>
      <a href="http://introtodeeplearning.com/">MIT Introduction to Deep Learning - 6.S191</a><br>Lecturer, January 2017 [<a href="https://www.youtube.com/watch?v=6QewMQT4iMM">video</a>]<br><br>
      <a href="https://misti.mit.edu/global-teaching-labs">MIT Global Teaching Labs - Istituto Tecnico Industriale Statale Tullio Buzzi di Prato</a><br>Instructor, January 2016<br><br>
      <a href="https://swe.mit.edu/outreach/middle_school/helloworld.html">MIT SWE - #HelloWorld</a><br>Instructor, Spring 2015 - Fall 2016 [<a href="https://drive.google.com/open?id=0Bw9g8vmIO_peflh5WlpEdHBESEdiakdIOVpjZTZPY3g3WWRJMUkyVTRheHFXVDROZUFJLWM">slides</a>]<br><br>
      <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-01sc-introduction-to-electrical-engineering-and-computer-science-i-spring-2011/">MIT Introduction to Electrical Engineering and Computer Science - 6.01</a><br>Student Lab Assistant, Spring 2014<br><br>
      <a href="https://www.khanacademy.org/talks-and-interviews/schools-using-khan-academy/v/khan-academy-s-discovery-lab-offers-hands-on-learning">Khan Academy - Discovery Lab</a><br>Teaching Assistant, Summer 2012</p>
    </div>
    <div id="other">
      <h2>Other</h2>
	I've released my NSF GRFP application statements for future applicants [<a href="resources/NSF_Personal_Statement_Victoria_Dean.pdf">personal</a>, <a href="resources/NSF_Research_Statement_Victoria_Dean.pdf">research</a>].<br><br>
	With the Dean's PhD Advisory Committee, I co-wrote a public letter, <a href="https://docs.google.com/document/d/1-WRYuLT-xQFOiv1yyxMUdFV26RGB9_jOFgz7Y_xaWuk">Towards Anti-Racist Change in the School of Computer Science</a>, which amassed more than 600 signatures in 2020.<br><br>
      I co-organized a 2020 NeurIPS workshop: <a href="https://montrealrobotics.ca/diffcvgp/">Differentiable vision, graphics, and physics in machine learning</a>.
      Outside of research, I enjoy <a href="https://www.goodreads.com/review/list/97438434?shelf=favorites">reading</a>, <a href="https://www.strava.com/athletes/9602014">hiking</a>, and <a href="images/cookies.gif">experimental baking</a>.<br><br>
      I co-founded <a href="http://codeforgood.mit.edu">Code for Good</a>, an MIT student group that works with Boston-area nonprofits on technical projects.<br><br>
      Languages: English (native), Mandarin (conversational), Spanish (beginner)</div>
    </div>
  </div>
</body>
</html>
OB
